{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea3f712-3d2d-477a-a10d-60dcb833589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas sentence-transformers faiss-cpu\n",
    "!pip install tensorflow==2.15.0 keras==2.15.0\n",
    "! pip install pandas sentence-transformers faiss-cpu scikit-learn matplotlib tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d22ac0c-7dfc-4bc5-a25b-c302cc225a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda create -n my_env python=3.10\n",
    "#conda activate my_env\n",
    "#pip install tensorflow==2.15.0 keras==2.15.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44b38fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c15829b3-da36-4a8e-a559-2f9d033d4bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>incident_number</th>\n",
       "      <th>application</th>\n",
       "      <th>error_code</th>\n",
       "      <th>microservice</th>\n",
       "      <th>description</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>resolution_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INC000005184952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AP:PRD:UR: Authorization has failed\\n\\nAlert T...</td>\n",
       "      <td>Changed Group assignment to Universal Reposito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>INC000005183351</td>\n",
       "      <td>DIGITAL_PLATFORM</td>\n",
       "      <td>ServiceException</td>\n",
       "      <td>ur-api-gateway</td>\n",
       "      <td>Cassandra timeout during read query at consist...</td>\n",
       "      <td>Stage:prod\\nMicroservice:\\tur-api-gateway\\nTra...</td>\n",
       "      <td>Changed Group assignment to Universal Reposito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INC000005183248</td>\n",
       "      <td>DIGITAL_PLATFORM</td>\n",
       "      <td>ServiceException</td>\n",
       "      <td>ur-api-gateway</td>\n",
       "      <td>Cassandra timeout during read query at consist...</td>\n",
       "      <td>Stage:prod\\nMicroservice:\\tur-api-gateway\\nTra...</td>\n",
       "      <td>Changed Group assignment to Universal Reposito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INC000005183246</td>\n",
       "      <td>DIGITAL_PLATFORM</td>\n",
       "      <td>ServiceException</td>\n",
       "      <td>ur-api-gateway</td>\n",
       "      <td>Cassandra timeout during read query at consist...</td>\n",
       "      <td>Stage:prod\\nMicroservice:\\tur-api-gateway\\nTra...</td>\n",
       "      <td>Changed Group assignment to Universal Reposito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>INC000005180860</td>\n",
       "      <td>Customer Communications-&gt;Digital-&gt;Presentment ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summary of the issue: ICMA - removal of digita...</td>\n",
       "      <td>Changed Group assignment to EDH CSM9 Assigned ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  incident_number  \\\n",
       "0           0  INC000005184952   \n",
       "1           1  INC000005183351   \n",
       "2           2  INC000005183248   \n",
       "3           3  INC000005183246   \n",
       "4           4  INC000005180860   \n",
       "\n",
       "                                         application        error_code  \\\n",
       "0                                                NaN               NaN   \n",
       "1                                   DIGITAL_PLATFORM  ServiceException   \n",
       "2                                   DIGITAL_PLATFORM  ServiceException   \n",
       "3                                   DIGITAL_PLATFORM  ServiceException   \n",
       "4  Customer Communications->Digital->Presentment ...               NaN   \n",
       "\n",
       "     microservice                                        description  \\\n",
       "0             NaN                                                NaN   \n",
       "1  ur-api-gateway  Cassandra timeout during read query at consist...   \n",
       "2  ur-api-gateway  Cassandra timeout during read query at consist...   \n",
       "3  ur-api-gateway  Cassandra timeout during read query at consist...   \n",
       "4             NaN                                                NaN   \n",
       "\n",
       "                                detailed_description  \\\n",
       "0  AP:PRD:UR: Authorization has failed\\n\\nAlert T...   \n",
       "1  Stage:prod\\nMicroservice:\\tur-api-gateway\\nTra...   \n",
       "2  Stage:prod\\nMicroservice:\\tur-api-gateway\\nTra...   \n",
       "3  Stage:prod\\nMicroservice:\\tur-api-gateway\\nTra...   \n",
       "4  Summary of the issue: ICMA - removal of digita...   \n",
       "\n",
       "                                 resolution_comments  \n",
       "0  Changed Group assignment to Universal Reposito...  \n",
       "1  Changed Group assignment to Universal Reposito...  \n",
       "2  Changed Group assignment to Universal Reposito...  \n",
       "3  Changed Group assignment to Universal Reposito...  \n",
       "4  Changed Group assignment to EDH CSM9 Assigned ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Data.xlsx')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa93e117-08cc-43fe-8572-1955345a9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_dict = df.set_index('incident_number')['resolution_comments'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87ef592a-e14e-464d-afe9-d624def931d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('incident_number', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4a54cdd-2b19-46b6-b618-156e9599d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate relevant columns into a single string for embedding\n",
    "df['text'] = df[['application', 'error_code', 'description', 'detailed_description']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7609640-24bb-4f72-a83e-347aeb97d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "058971d8-0654-40c7-893f-aefb95dc690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e2ba1e5-3467-4a14-b9e7-777b5ff33a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a678a01b-28ba-460c-b9d6-4215c7c3ff7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_number</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>INC000005184952</th>\n",
       "      <td>AP:PRD:UR: Authorization has failed\\n\\nAlert T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INC000005183351</th>\n",
       "      <td>DIGITAL_PLATFORM ServiceException Cassandra ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INC000005183248</th>\n",
       "      <td>DIGITAL_PLATFORM ServiceException Cassandra ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INC000005183246</th>\n",
       "      <td>DIGITAL_PLATFORM ServiceException Cassandra ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INC000005180860</th>\n",
       "      <td>Customer Communications-&gt;Digital-&gt;Presentment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INC000005180399</th>\n",
       "      <td>DIGITAL_PLATFORM BENGAL_TIGER (TraceId=65b7ced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INC000005180243</th>\n",
       "      <td>DIGITAL_PLATFORM BENGAL_TIGER (TraceId=65b7cec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INC000005178679</th>\n",
       "      <td>DIGITAL_PLATFORM ReplyException Timed out afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INC000005178635</th>\n",
       "      <td>DIGITAL_PLATFORM ServiceException operation ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INC000005178634</th>\n",
       "      <td>DIGITAL_PLATFORM ServiceException operation ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              text\n",
       "incident_number                                                   \n",
       "INC000005184952  AP:PRD:UR: Authorization has failed\\n\\nAlert T...\n",
       "INC000005183351  DIGITAL_PLATFORM ServiceException Cassandra ti...\n",
       "INC000005183248  DIGITAL_PLATFORM ServiceException Cassandra ti...\n",
       "INC000005183246  DIGITAL_PLATFORM ServiceException Cassandra ti...\n",
       "INC000005180860  Customer Communications->Digital->Presentment ...\n",
       "INC000005180399  DIGITAL_PLATFORM BENGAL_TIGER (TraceId=65b7ced...\n",
       "INC000005180243  DIGITAL_PLATFORM BENGAL_TIGER (TraceId=65b7cec...\n",
       "INC000005178679  DIGITAL_PLATFORM ReplyException Timed out afte...\n",
       "INC000005178635  DIGITAL_PLATFORM ServiceException operation ti...\n",
       "INC000005178634  DIGITAL_PLATFORM ServiceException operation ti..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d913a909-b32c-4472-9a2c-aadc7e5e11c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rc11692\\AppData\\Local\\Temp\\ipykernel_31620\\2578418679.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  data.text[4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Customer Communications->Digital->Presentment (Including Legacy PostEdge) Summary of the issue: ICMA - removal of digital onserts for 1099 tax forms\\nDescription of the issue: ICMA is requesting we remove the digital onsert from the forms as it is pulling in the previous year’s form. (Due to time constraints, this year’s form was not included but the previous year’s is still being pulled in)\\nSeverity: Sev3\\nClients Affected: Single\\nClients Affected (Single): ICMA\\nClient number (Single): I00022\\nActual Incident Start Time: 1/25/2024 9:00 AM\\nBusiness Impact?: Yes\\nBusiness Impact: Yes \\nClient Impact: Yes \\nBusiness Unit: BRCC\\nAffected Application: Customer Communications->Digital->Presentment (Including Legacy PostEdge)\\nIdentified Source: Client Detected\\nEnvironment: Production\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2236a65b-1cc8-4aa7-bcfb-236ddf45c54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43fad67be62406ba0c65efba64d9cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(data['text'].tolist(), show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e42b8b2c-4ed4-4499-afc4-2ebb92452e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07375074,  0.06568636, -0.04863684, ..., -0.04706039,\n",
       "        -0.08331089,  0.066782  ],\n",
       "       [-0.02130117, -0.03041642, -0.0099752 , ..., -0.04174381,\n",
       "        -0.0460832 , -0.00206137],\n",
       "       [-0.00408928, -0.03323755, -0.00500118, ..., -0.03572897,\n",
       "        -0.06078001, -0.00911633],\n",
       "       ...,\n",
       "       [-0.04008536, -0.01256368, -0.01236878, ...,  0.00593633,\n",
       "        -0.07521831, -0.02346144],\n",
       "       [-0.01994997, -0.00201161, -0.03769414, ...,  0.02792372,\n",
       "        -0.03477802, -0.024237  ],\n",
       "       [-0.01687484, -0.00313686, -0.03950549, ...,  0.02572631,\n",
       "        -0.03553012, -0.0249915 ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a430fb8-c4ff-4e39-a503-f9189ee14cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings to a numpy array\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Initialize Faiss index\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the index to disk\n",
    "faiss.write_index(index, 'incident_index.faiss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26075eaf-88a3-4fe8-9f00-21a9692f7bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution of above one is Changed Group assignment to EDH CSM9 Assigned To: givensr by givensr Changed Group assignment to EDH INCIDENT MGMT Per Casie Thompson, this is a duplicate - the issue has already been taken care of. This ticket can be closed. \n",
      "***MIR3 PAGE RESPONSE***\n",
      "From: Gautam Ramalingam \n",
      "Selected Response: Accept \n",
      "At: 1/29/2024 5:41:44 PM EST\n",
      "\n",
      "https://remtieritsm.broadridge.net/arsys/forms/remproditsm/BR%3AMIR3%3ASearchUI?F536870975=1&F536870976=MIR300001090759\n",
      "\n",
      "https://webnotify.mir3.com/prepareEventHist.do?eventHistId=3e76c3f4-0003-3000-80c0-fceb55463ffe ***MIR3 PAGE TRIGGERED*** \n",
      "Sent to: BRCC UR Core team \n",
      "At 1/29/2024 5:36:12 PM EST\n",
      "Message: Please review and address incident ICMA - removal of digital onserts for 1099 tax forms. Please reference incident number 5180860\n",
      "\n",
      " Incident Communication Channel: \n",
      "\n",
      "Page sent by: Richard J Givens\n",
      "https://smartit.broadridge.net/smartit/app/#/incident/IDGAA5V0H1S9XASIBMBHSHBC0GYUYY\n",
      "Note: Incident link works only on BR network\n",
      "https://remtieritsm.broadridge.net/arsys/forms/remproditsm/BR%3AMIR3%3ASearchUI?F536870975=1&F536870976=MIR300001090759\n",
      "\n",
      "https://webnotify.mir3.com/prepareEventHist.do?eventHistId=3e76c3f4-0003-3000-80c0-fceb55463ffe Changed Group assignment to Universal Repository This cannot be done by Presentment Team. Presentment UI & API only display UR data served by DIS API.\n",
      "This should be assigned to UR team. \n",
      "***MIR3 PAGE RESPONSE***\n",
      "From: Dimitrios Varsos \n",
      "Selected Response: Accept \n",
      "At: 1/29/2024 5:29:44 PM EST\n",
      "\n",
      "https://remtieritsm.broadridge.net/arsys/forms/remproditsm/BR%3AMIR3%3ASearchUI?F536870975=1&F536870976=MIR300001090660\n",
      "\n",
      "https://webnotify.mir3.com/prepareEventHist.do?eventHistId=3e76c356-0003-3000-80c0-fceb55463ffe ***MIR3 PAGE TRIGGERED*** \n",
      "Sent to: x247 - DEV PostEdge Web Dev - Front End US \n",
      "At 1/29/2024 5:29:14 PM EST\n",
      "Message: Please review / address incident ICMA - removal of digital onserts for 1099 tax forms. Please reference incident number 5180860\n",
      "\n",
      " Incident Communication Channel: \n",
      "\n",
      "Page sent by: Richard J Givens\n",
      "https://smartit.broadridge.net/smartit/app/#/incident/IDGAA5V0H1S9XASIBMBHSHBC0GYUYY\n",
      "Note: Incident link works only on BR network\n",
      "https://remtieritsm.broadridge.net/arsys/forms/remproditsm/BR%3AMIR3%3ASearchUI?F536870975=1&F536870976=MIR300001090660\n",
      "\n",
      "https://webnotify.mir3.com/prepareEventHist.do?eventHistId=3e76c356-0003-3000-80c0-fceb55463ffe Changed Group assignment to Digital Presentment Assigned To: givensr by givensr Changed Group assignment to EDH INCIDENT MGMT This ticket was created from the service request system. Business Impact -  Yes \n",
      "\n",
      "Client Impact - Yes  Severity Marked: Sev3 Changed Group assignment to Distributed Systems Monitoring\n"
     ]
    }
   ],
   "source": [
    "def search_similar_incidents(query, top_n=1):\n",
    "    query_embedding = model.encode([query])\n",
    "    D, I = index.search(np.array(query_embedding), top_n)\n",
    "    \n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        incident_id = df.index[idx]\n",
    "        results.append((incident_id, df.loc[incident_id]['text']))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "query = \"Summary of the issue: ICMA - removal of digital onserts for 1099 tax forms\\nDescription of the issue: ICMA is requesting we remove the digital onsert f\"\n",
    "similar_incidents = search_similar_incidents(query)\n",
    "for incident_id, text in similar_incidents:\n",
    "    print(f\"resolution of above one is {incident_dict[incident_id]}\")\n",
    "    #print(f\"Incident ID: {incident_id}\\nText: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376d56e-b6da-4390-a97a-fd42bd73c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save local and use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8be66232-6573-4429-98ac-8b350b9d4afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d5a6ce1ac345c9968234de8c1e3f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load your CSV data\n",
    "#df = pd.read_csv('your_file.csv')\n",
    "df = pd.read_excel('Data.xlsx')\n",
    "df['text'] = df[['application', 'error_code', 'description', 'detailed_description']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "df.set_index('incident_number', inplace=True)\n",
    "\n",
    "df = df[:5]\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(df['text'].tolist(), show_progress_bar=True)\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Initialize Faiss index\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the index to disk\n",
    "faiss.write_index(index, 'incident_index.faiss')\n",
    "\n",
    "# Save the DataFrame to disk\n",
    "df.to_csv('incident_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6415e46-d4f6-4cf9-88d5-1e8c33bbe094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident ID: INC000005183248\n",
      "Text: DIGITAL_PLATFORM ServiceException Cassandra timeout during read query at consistency LOCAL_QUORUM (2 responses were required but only 0 replica responded). In case this was generated during read repair, the consistency level is not representative of the actual consistency. Stage:prod\n",
      "Microservice:\tur-api-gateway\n",
      "Trace Data:\t\t\t\t(TraceId=65b94c59cb6c3e2b1726523df5e2289c, ParentSpanId=d1d9e5993a880da5, SpanId=b25055601044fa67)\n",
      "Application:\t\tDIGITAL_PLATFORM\n",
      "\n",
      "User Name:\t\tdp_prod\n",
      "\n",
      "Error Code:\t\tServiceException\n",
      "\n",
      "Description:\t\tCassandra timeout during read query at consistency LOCAL_QUORUM (2 responses were required but only 0 replica responded). In case this was generated during read repair, the consistency level is not representative of the actual consistency.\n",
      "\n",
      "Incident ID: INC000005183246\n",
      "Text: DIGITAL_PLATFORM ServiceException Cassandra timeout during read query at consistency LOCAL_QUORUM (2 responses were required but only 0 replica responded). In case this was generated during read repair, the consistency level is not representative of the actual consistency. Stage:prod\n",
      "Microservice:\tur-api-gateway\n",
      "Trace Data:\t\t\t\t(TraceId=65b94c59cb6c3e2b1726523df5e2289c, ParentSpanId=d1d9e5993a880da5, SpanId=b25055601044fa67)\n",
      "Application:\t\tDIGITAL_PLATFORM\n",
      "\n",
      "User Name:\t\tdp_prod\n",
      "\n",
      "Error Code:\t\tServiceException\n",
      "\n",
      "Description:\t\tCassandra timeout during read query at consistency LOCAL_QUORUM (2 responses were required but only 0 replica responded). In case this was generated during read repair, the consistency level is not representative of the actual consistency.\n",
      "\n",
      "Incident ID: INC000005183351\n",
      "Text: DIGITAL_PLATFORM ServiceException Cassandra timeout during read query at consistency LOCAL_QUORUM (timeout while waiting for repair of inconsistent replica). In case this was generated during read repair, the consistency level is not representative of the actual consistency. Stage:prod\n",
      "Microservice:\tur-api-gateway\n",
      "Trace Data:\t\t\t\t(TraceId=65b94dd8541df0880ccf3868aa1bb2ed, ParentSpanId=a95aa61b62356094, SpanId=a5beeadd164df451)\n",
      "Application:\t\tDIGITAL_PLATFORM\n",
      "\n",
      "User Name:\t\tdp_prod\n",
      "\n",
      "Error Code:\t\tServiceException\n",
      "\n",
      "Description:\t\tCassandra timeout during read query at consistency LOCAL_QUORUM (timeout while waiting for repair of inconsistent replica). In case this was generated during read repair, the consistency level is not representative of the actual consistency.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the Faiss index from disk\n",
    "index = faiss.read_index('incident_index.faiss')\n",
    "\n",
    "# Load the DataFrame from disk\n",
    "df = pd.read_csv('incident_data.csv', index_col='incident_number')\n",
    "\n",
    "# Initialize the model for embedding queries\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def search_similar_incidents(query, top_n=3):\n",
    "    query_embedding = model.encode([query])\n",
    "    D, I = index.search(np.array(query_embedding), top_n)\n",
    "    \n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        incident_id = df.index[idx]\n",
    "        results.append((incident_id, df.loc[incident_id]['text']))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "query = \"Cassandra timeout during read query\"\n",
    "similar_incidents = search_similar_incidents(query)\n",
    "for incident_id, text in similar_incidents:\n",
    "    print(f\"Incident ID: {incident_id}\\nText: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a23c73-1811-4e51-9c96-7c6e14b10bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2898e79f-8ff7-44c2-b895-c38d45208263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_excel('Data.xlsx')\n",
    "\n",
    "df = df\n",
    "\n",
    "# Concatenate relevant columns into a single string for embedding\n",
    "df['text'] = df[['application', 'error_code', 'description', 'detailed_description']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set the incident_number as the index for both\n",
    "train_df.set_index('incident_number', inplace=True)\n",
    "val_df.set_index('incident_number', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a8892ac-cac6-4927-9d52-aeae0f360cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15dc0faabf74e4d90ade8c17bd9cde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Initialize the model for embedding queries\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for the training set\n",
    "train_embeddings = model.encode(train_df['text'].tolist(), show_progress_bar=True)\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "\n",
    "# Normalize the embeddings for cosine similarity\n",
    "faiss.normalize_L2(train_embeddings)\n",
    "\n",
    "# Initialize Faiss index\n",
    "d = train_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(d)  # IP stands for Inner Product which is equivalent to cosine similarity on normalized vectors\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(train_embeddings)\n",
    "\n",
    "# Create incident dictionary\n",
    "incident_dict = train_df['resolution_comments'].to_dict()\n",
    "\n",
    "# Save the index and incident dictionary\n",
    "faiss.write_index(index, 'incident_index_cosine.faiss')\n",
    "import pickle\n",
    "with open('incident_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(incident_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "575a458c-234d-42cd-a0b2-b5cf8d7908cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ef1f8e840b449cbf9329be6772ceb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Faiss index and incident dictionary\n",
    "index = faiss.read_index('incident_index_cosine.faiss')\n",
    "with open('incident_dict.pkl', 'rb') as f:\n",
    "    incident_dict = pickle.load(f)\n",
    "\n",
    "# Generate embeddings for the validation set\n",
    "val_embeddings = model.encode(val_df['text'].tolist(), show_progress_bar=True)\n",
    "faiss.normalize_L2(val_embeddings)\n",
    "\n",
    "# Perform similarity search and evaluate\n",
    "def search_similar_incidents(query_embedding, top_n=1):\n",
    "    D, I = index.search(np.array([query_embedding]), top_n)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        incident_id = train_df.index[idx]\n",
    "        results.append((incident_id, train_df.loc[incident_id]['text']))\n",
    "    return results\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = 0\n",
    "for i, row in val_df.iterrows():\n",
    "    query_embedding = model.encode([row['text']])[0]\n",
    "    result = search_similar_incidents(query_embedding, top_n=1)\n",
    "    if result and incident_dict[result[0][0]] == row['resolution_comments']:\n",
    "        correct += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "708bc75b-bac6-4cf7-a1a0-1014915cd4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct / len(val_df)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3047d4-3235-48ae-9173-c61178879c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99d822-2314-4b6e-a270-1ca0fab41fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd2fa2-1b80-4b31-b624-cdf3ecc242d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d166299e-0816-4d50-a989-d6b39dacdee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbac5a195324d1995c35a17d75710b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_excel('Data.xlsx')\n",
    "\n",
    "# Concatenate relevant columns into a single string for embedding\n",
    "df['text'] = df[['application', 'error_code', 'description', 'detailed_description']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "df.set_index('incident_number', inplace=True)\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(df['text'].tolist(), show_progress_bar=True)\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Normalize the embeddings for cosine similarity\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "# Initialize Faiss index\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(d)  # IP stands for Inner Product which is equivalent to cosine similarity on normalized vectors\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the index and DataFrame\n",
    "faiss.write_index(index, 'incident_index_cosine.faiss')\n",
    "df.to_csv('incident_data.csv')\n",
    "incident_dict = df['resolution_comments'].to_dict()\n",
    "with open('incident_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(incident_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a502dc0-99fd-4f71-88a9-0059b79207e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample for validation\n",
    "val_df = df.sample(frac=0.2, random_state=42)  # Using 20% of the data for validation\n",
    "\n",
    "# Drop the selected validation samples from the original DataFrame to simulate a training dataset\n",
    "train_df = df.drop(val_df.index)\n",
    "\n",
    "# Reduce the text data length for validation\n",
    "val_df['text'] = val_df['text'].apply(lambda x: ' '.join(x.split()[:50]))  # Using first 50 words as an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba816ce2-e39e-43e5-8024-ccaabdd0e820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8821656050955414\n"
     ]
    }
   ],
   "source": [
    "# Load the Faiss index and incident dictionary\n",
    "index = faiss.read_index('incident_index_cosine.faiss')\n",
    "df = pd.read_csv('incident_data.csv', index_col='incident_number')\n",
    "with open('incident_dict.pkl', 'rb') as f:\n",
    "    incident_dict = pickle.load(f)\n",
    "\n",
    "def search_similar_incidents(query_embedding, top_n=1):\n",
    "    D, I = index.search(np.array([query_embedding]), top_n)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        incident_id = df.index[idx]\n",
    "        results.append((incident_id, df.loc[incident_id]['text']))\n",
    "    return results\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "correct = 0\n",
    "for i, row in val_df.iterrows():\n",
    "    query_embedding = model.encode([row['text']])[0]\n",
    "    result = search_similar_incidents(query_embedding, top_n=1)\n",
    "    if result and incident_dict[result[0][0]] == row['resolution_comments']:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(val_df)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe39ba9-5c46-4e33-8104-e6e11d5b12fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing validation set: 100%|██████████████████████████████████████████████████████████████████| 628/628 [04:32<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8821656050955414\n",
      "Recall: 0.8821656050955414\n",
      "F1-score: 0.8821656050955414\n",
      "Accuracy: 0.8821656050955414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, precision_recall_curve, accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the Faiss index and incident dictionary\n",
    "index = faiss.read_index('incident_index_cosine.faiss')\n",
    "df = pd.read_csv('incident_data.csv', index_col='incident_number')\n",
    "with open('incident_dict.pkl', 'rb') as f:\n",
    "    incident_dict = pickle.load(f)\n",
    "\n",
    "def search_similar_incidents(query_embedding, top_n=1):\n",
    "    D, I = index.search(np.array([query_embedding]), top_n)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        incident_id = df.index[idx]\n",
    "        results.append((incident_id, df.loc[incident_id]['text']))\n",
    "    return results\n",
    "\n",
    "# Calculate precision, recall, and accuracy on the validation set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "correct_predictions = []\n",
    "wrong_predictions = []\n",
    "\n",
    "for i, row in tqdm(val_df.iterrows(), total=val_df.shape[0], desc=\"Processing validation set\"):\n",
    "    query_embedding = model.encode([row['text']])[0]\n",
    "    result = search_similar_incidents(query_embedding, top_n=1)\n",
    "    true_label = row['resolution_comments']\n",
    "    y_true.append(true_label)\n",
    "    if result:\n",
    "        predicted_label = incident_dict[result[0][0]]\n",
    "        y_pred.append(predicted_label)\n",
    "        if true_label == predicted_label:\n",
    "            correct_predictions.append((i, row['text'], true_label))\n",
    "        else:\n",
    "            wrong_predictions.append((i, row['text'], true_label, predicted_label))\n",
    "    else:\n",
    "        y_pred.append(\"\")\n",
    "        wrong_predictions.append((i, row['text'], true_label, \"\"))\n",
    "\n",
    "# Convert lists to numpy arrays for evaluation\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Calculate precision, recall, and f1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Create DataFrames for correct and wrong predictions\n",
    "correct_df = pd.DataFrame(correct_predictions, columns=['incident_id', 'text', 'true_label'])\n",
    "wrong_df = pd.DataFrame(wrong_predictions, columns=['incident_id', 'text', 'true_label', 'predicted_label'])\n",
    "\n",
    "# Display DataFrames\n",
    "correct_df.to_csv('correct_predictions.csv', index=False)\n",
    "wrong_df.to_csv('wrong_predictions.csv', index=False)\n",
    "\n",
    "print(\"Correct Predictions DataFrame:\")\n",
    "print(correct_df.head())\n",
    "\n",
    "print(\"Wrong Predictions DataFrame:\")\n",
    "print(wrong_df.head())\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_true, y_pred, pos_label=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall_vals, precision_vals, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f3bb9-270f-4e5d-b5c9-cff9623779c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
